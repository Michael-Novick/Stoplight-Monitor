# Michael Novick
# July 2017
# Adapted from code written by Dr. Steve Mitchell

import numpy as np
#import matplotlib
#import matplotlib.pyplot as plt
#import argparse
import cv2
import imutils
import time


def main():
    height, width, screen_center, cap = initialize_video_stream()
    stoplights = identify_stoplights(cap, height)
    main_stoplight = identify_main_stoplight(stoplights, screen_center)
    color = monitor_stoplight(main_stoplight, cap, height, width)
    print(color)


def initialize_video_stream():
    # identify filename of video to be analyzed
    cap = cv2.VideoCapture('MOV_0002.AVI')
    # can also identify computer port with incoming camera stream
    height, width = cap.get(cv2.CAP_PROP_FRAME_HEIGHT), cap.get(cv2.CAP_PROP_FRAME_WIDTH)
    screen_center = width / 2
    return height, width, screen_center, cap


def identify_stoplights(cap, height):  # todo
    stoplights = []
    snip_height = height / 2
    while cap.isOpened():  # does the video ever close?
        # read video frame & show on screen
        ret, frame = cap.read()  # ret should be true or 1, frame should be a 3D array?
        frame = frame[0:int(snip_height), :]

        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        # thresh = 200
        # frame = cv2.threshold(frame, thresh, 255, cv2.THRESH_BINARY)[1]
        # cv2.imshow("Black/White", frame)

        # blur image to help with edge detection
        blurred = cv2.GaussianBlur(frame, (7, 7), 0)
        # cv2.imshow("Blurred", blurred)

        # identify edges & show on screen
        edged = cv2.Canny(blurred, 30, 150)
        cv2.imshow("Edged", edged)

        # perform full Hough Transform to identify lane lines
        lines = cv2.HoughLines(edged, 1, np.pi / 180, 25)

        # define arrays for left and right lanes
        rho_left = []
        theta_left = []
        rho_right = []
        theta_right = []

        # ensure cv2.HoughLines found at least one line
        if lines is not None:

            # loop through all of the lines found by cv2.HoughLines
            for i in range(0, len(lines)):

                # evaluate each row of cv2.HoughLines output 'lines'
                for rho, theta in lines[i]:

                    # collect left lanes
                    # if theta < np.pi/2 and theta > np.pi/4:
                    rho_left.append(rho)
                    theta_left.append(theta)

                    # plot all lane lines for DEMO PURPOSES ONLY
                    a = np.cos(theta); b = np.sin(theta)
                    x0 = a * rho; y0 = b * rho
                    x1 = int(x0 + 400 * (-b)); y1 = int(y0 + 400 * (a))
                    x2 = int(x0 - 600 * (-b)); y2 = int(y0 - 600 * (a))

                    cv2.line(frame, (x1, y1), (x2, y2), (0, 0, 255), 1)

                    # collect right lanes
                    # if theta > np.pi/2 and theta < 3*np.pi/4:
                    rho_right.append(rho)
                    theta_right.append(theta)

                    # plot all lane lines for DEMO PURPOSES ONLY
                    a = np.cos(theta); b = np.sin(theta)
                    x0 = a * rho; y0 = b * rho
                    x1 = int(x0 + 400 * (-b)); y1 = int(y0 + 400 * (a))
                    x2 = int(x0 - 600 * (-b)); y2 = int(y0 - 600 * (a))
                    cv2.line(frame, (x1, y1), (x2, y2), (0, 0, 255), 1)


        vertices = None  # identify vertices with processing and feature detection
        for corners in vertices:
            if True:  # return to this function
                stoplights.append(Stoplight(corners))
    return stoplights
    # in this method we need to iterate through the video stream until stoplights are detected. More iterations need to
    # occur after the first stoplights are detected, and work needs to be done to tell each stoplight apart. Optical
    # flow may be necessary to track individual stoplights, so duplicate detection is avoided. Once all stoplights are
    # detected the code can proceed

    # maybe stoplights can be detected from the center >> outwards, and first stoplight detected is used. Perhaps use
    # aspect ratio, because hypothetically the aspect ratio of a stoplight should be roughly 3:1 (3 circles in a row)


def identify_main_stoplight(stoplights, screen_center):
    difference = screen_center * 2
    for stoplight in stoplights:
        distance_from_center = np.abs(stoplight.find_stoplight_center()-screen_center)
        if distance_from_center <= difference:
            winning_stoplight = stoplight
            difference = distance_from_center
    main_stoplight = MainStoplight(winning_stoplight)
    return main_stoplight


def monitor_stoplight(stoplight, cap, height, width):  # todo
    # Write code to monitor stoplight status
    # check if need to change snip based on condition

    snip_bounds = redefine_snip(stoplight, height, width)

    while cap.isOpened():  # does the video ever close?
        # read video frame & show on screen
        ret, frame = cap.read()  # ret should be true or 1, frame should be a 3D array?
        if window_resize_check(stoplight):
            stoplight.redefine_position(stoplight)
            snip_bounds = redefine_snip(stoplight, height, width)
        snip = frame[snip_bounds[0, 1]:snip_bounds[1, 1], snip_bounds[0, 0]:snip_bounds[1, 0]]
        color = detect_signal(snip)
        # if color == 'green':
        #     break
        return color
    # snip_bounds = stoplight.vertices
    # return color


def window_resize_check(stoplight): # todo
    # optical flow stuff, see if stoplight is getting too close to snipping bounds
    if None:
        return True
    else:
        return False


def detect_signal(frame):  # todo
    color = 'red'
    return color
    # image processing is required here to identify the color of the traffic signal


def redefine_snip(stoplight, height, width):  # todo
    snip = np.array()
    snip[0, 0] = stoplight.vertices[1, 1] - stoplight.width
    snip[0, 1] = stoplight.vertices[1, 0] - stoplight.height
    snip[1, 0] = stoplight.vertices[3, 1] + stoplight.width
    snip[1, 1] = stoplight.vertices[3, 0] + stoplight.height

    if snip[0, 0] < 0:
        snip[0, 0] = 0
    if snip[0, 1] < 0:
        snip[0, 1] = 0
    if snip[1, 0] > width:
        snip[1, 0] = width
    if snip[1, 1] > height:
        snip[1, 1] = height

    return snip


class Stoplight:
    def __init__(self, vertices):
        self.vertices = vertices
        self.height = vertices[3, 0] - vertices[0, 0]
        self.width = vertices[3, 1] - vertices[2, 1]

    def find_stoplight_center(self):
        stoplight_center = np.mean(self.vertices[:, 1])
        return stoplight_center

    def redefine_position(self):  # Todo
        # write code (optical flow?) to redefine stoplight location
        vertices = None
        self.vertices = vertices
        return None


class MainStoplight(Stoplight):
    def __init__(self, status):
        self.status = status


if __name__ == '__main__':
    main()
